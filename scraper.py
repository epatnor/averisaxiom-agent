# scraper.py

import requests
import feedparser
import os

# === GOOGLE NEWS ===
def fetch_google_news():
    """
    H√§mtar relevanta nyheter fr√•n Google News RSS-feed.
    Filtrerar bort sport, k√§ndisar, underh√•llning etc.
    Beh√•ller bara nyheter om politik, teknik, AI och vetenskap.
    """
    print("üîç Fetching Google News RSS...")

    # Lista √∂ver godk√§nda nyckelord
    relevant_keywords = [
        "world", "politics", "election", "president", "government",
        "tech", "technology", "AI", "artificial intelligence",
        "science", "research", "space", "innovation"
    ]

    feed_url = "https://news.google.com/rss?hl=en-US&gl=US&ceid=US:en"
    feed = feedparser.parse(feed_url)
    results = []

    for entry in feed.entries:
        title_lower = entry.title.lower()
        # Beh√•ll bara nyheter som inneh√•ller n√•got relevant nyckelord
        if any(keyword in title_lower for keyword in relevant_keywords):
            results.append({
                "title": entry.title,
                "type": "auto",
                "source": "Google News"
            })

    print(f"‚úÖ Retained {len(results)} relevant headlines from Google News.")
    return results


# === YOUTUBE VIDEOS ===
def fetch_youtube_videos():
    """
    H√§mtar YouTube-videotitlar baserat p√• flera relevanta teman.
    Kr√§ver en milj√∂variabel: YOUTUBE_API_KEY.
    """
    print("üîç Fetching YouTube videos...")
    API_KEY = os.getenv("YOUTUBE_API_KEY")

    if not API_KEY:
        print("‚ö†Ô∏è WARNING: No YOUTUBE_API_KEY found.")
        return []

    # Fokusfr√•gor f√∂r olika √§mnesomr√•den
    queries = [
        "world politics",
        "american elections",
        "AI breakthroughs",
        "tech news",
        "space exploration",
        "scientific discoveries"
    ]

    results = []

    for query in queries:
        url = (
            "https://www.googleapis.com/youtube/v3/search"
            f"?part=snippet&q={query}&type=video&maxResults=5&key={API_KEY}"
        )
        try:
            response = requests.get(url)
            data = response.json()
            for item in data.get("items", []):
                title = item['snippet']['title']
                results.append({
                    "title": title,
                    "type": "auto",
                    "source": "YouTube"
                })
        except Exception as e:
            print(f"‚ùå Error fetching YouTube query '{query}': {e}")

    print(f"‚úÖ Retrieved {len(results)} relevant YouTube titles.")
    return results
